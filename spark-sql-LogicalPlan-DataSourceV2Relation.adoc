== [[DataSourceV2Relation]] DataSourceV2Relation Leaf Logical Operator

`DataSourceV2Relation` is a <<spark-sql-LogicalPlan-LeafNode.adoc#, leaf logical operator>> that represents a scan in the <<spark-sql-data-source-api-v2.adoc#, Data Source API V2>>.

`DataSourceV2Relation` is <<create, created>> exclusively when `DataFrameReader` is requested to <<spark-sql-DataFrameReader.adoc#load, "load" data (as a DataFrame)>> (from a data source with <<spark-sql-ReadSupport.adoc#, ReadSupport>>).

[[creating-instance]]
`DataSourceV2Relation` takes the following to be created:

* [[source]] <<spark-sql-DataSourceV2.adoc#, DataSourceV2>>
* [[output]] Output <<spark-sql-Expression-AttributeReference.adoc#, attributes>> (`Seq[AttributeReference]`)
* [[options]] Options (`Map[String, String]`)
* [[tableIdent]] Optional `TableIdentifier` (default: undefined, i.e. `None`)
* [[userSpecifiedSchema]] User-defined <<spark-sql-StructType.adoc#, schema>> (default: undefined, i.e. `None`)

`DataSourceV2Relation` initializes the <<internal-registries, internal registries and counters>>.

=== [[create]] Creating DataSourceV2Relation Instance -- `create` Factory Method

[source, scala]
----
create(
  source: DataSourceV2,
  options: Map[String, String],
  tableIdent: Option[TableIdentifier] = None,
  userSpecifiedSchema: Option[StructType] = None): DataSourceV2Relation
----

`create` requests the given <<spark-sql-DataSourceV2.adoc#, DataSourceV2>> to create a <<spark-sql-DataSourceReader.adoc#, DataSourceReader>> (with the given options and user-specified schema).

`create` finds the table in the given options unless the optional `tableIdent` is defined.

In the end, `create` <<creating-instance, creates a DataSourceV2Relation>>.

NOTE: `create` is used exclusively when `DataFrameReader` is requested to <<spark-sql-DataFrameReader.adoc#load, "load" data (as a DataFrame)>> (from a data source with <<spark-sql-ReadSupport.adoc#, ReadSupport>>).
