== [[CacheManager]] CacheManager -- In-Memory Cache for Tables and Views

`CacheManager` is an in-memory cache (_registry_) for structured queries (by their link:spark-sql-LogicalPlan.adoc[logical plans]).

`CacheManager` is shared across `SparkSessions` through link:spark-sql-SparkSession.adoc#sharedState[SharedState].

[source, scala]
----
val spark: SparkSession = ...
spark.sharedState.cacheManager
----

NOTE: A Spark developer can use `CacheManager` to cache ``Dataset``s using link:spark-sql-caching.adoc#cache[cache] or link:spark-sql-caching.adoc#persist[persist] operators.

`CacheManager` uses the <<cachedData, cachedData>> internal registry to manage cached structured queries and their link:spark-sql-LogicalPlan-InMemoryRelation.adoc[InMemoryRelation] cached representation.

`CacheManager` <<isEmpty, can be empty>>.

[[CachedData]]
[[plan]]
[[cachedRepresentation]]
`CacheManager` uses `CachedData` data structure for managing <<cachedData, cached structured queries>> with the <<spark-sql-LogicalPlan.adoc#, LogicalPlan>> (of a structured query) and a corresponding <<spark-sql-LogicalPlan-InMemoryRelation.adoc#, InMemoryRelation>> leaf logical operator.

=== [[cachedData]] Cached Structured Queries -- `cachedData` Internal Registry

[source, scala]
----
cachedData: LinkedList[CachedData]
----

`cachedData` is a collection of <<CachedData, CachedData>>.

A new `CachedData` added when `CacheManager` is requested to:

* <<cacheQuery, cacheQuery>>

* <<recacheByCondition, recacheByCondition>>

A `CachedData` removed when `CacheManager` is requested to:

* <<uncacheQuery, uncacheQuery>>

* <<recacheByCondition, recacheByCondition>>

All `CachedData` removed (cleared) when `CacheManager` is requested to <<clearCache, clearCache>>

=== [[invalidateCachedPath]] `invalidateCachedPath` Method

CAUTION: FIXME

=== [[invalidateCache]] `invalidateCache` Method

CAUTION: FIXME

=== [[lookupCachedData]] `lookupCachedData` Method

CAUTION: FIXME

=== [[uncacheQuery]] `uncacheQuery` Method

CAUTION: FIXME

=== [[isEmpty]] `isEmpty` Method

CAUTION: FIXME

=== [[cacheQuery]] Caching Structured Query (Registering Analyzed Logical Plan as InMemoryRelation) -- `cacheQuery` Method

[source, scala]
----
cacheQuery(
  query: Dataset[_],
  tableName: Option[String] = None,
  storageLevel: StorageLevel = MEMORY_AND_DISK): Unit
----

`cacheQuery` adds the link:spark-sql-Dataset.adoc#logicalPlan[analyzed logical plan] of the input `query` to the <<cachedData, cachedData>> internal registry of cached queries.

Internally, `cacheQuery` firstly requests the input `query` for the link:spark-sql-Dataset.adoc#logicalPlan[analyzed logical plan] and creates a link:spark-sql-LogicalPlan-InMemoryRelation.adoc#apply[InMemoryRelation] with the following properties:

* link:spark-sql-properties.adoc#spark.sql.inMemoryColumnarStorage.compressed[spark.sql.inMemoryColumnarStorage.compressed] (enabled by default)

* link:spark-sql-properties.adoc#spark.sql.inMemoryColumnarStorage.batchSize[spark.sql.inMemoryColumnarStorage.batchSize] (default: `10000`)

* Input `storageLevel` storage level

* link:spark-sql-QueryExecution.adoc#executedPlan[Optimized physical query plan] (after requesting `SessionState` to link:spark-sql-SessionState.adoc#executePlan[execute] the analyzed logical plan)

* Input `tableName`

* link:spark-sql-LogicalPlanStats.adoc#stats[Statistics] of the analyzed query plan

`cacheQuery` then creates a <<CachedData, CachedData>> (for the analyzed query plan and the `InMemoryRelation`) and adds it to the <<cachedData, cachedData>> internal registry.

If the input `query` has already been cached, `cacheQuery` simply prints the following WARN message to the logs and exits (i.e. does nothing but printing out the WARN message):

```
WARN CacheManager: Asked to cache already cached data.
```

[NOTE]
====
`cacheQuery` is used when:

* <<spark-sql-dataset-operators.adoc#persist, Dataset.persist>> basic action is used

* `CatalogImpl` is requested to <<spark-sql-CatalogImpl.adoc#cacheTable, cache a table or view in-memory>> or <<spark-sql-CatalogImpl.adoc#refreshTable, refresh a table>>
====

=== [[clearCache]] Removing All Cached Tables (From In-Memory Cache) -- `clearCache` Method

[source, scala]
----
clearCache(): Unit
----

`clearCache` acquires a write lock and unpersists ``RDD[CachedBatch]``s of the queries in <<cachedData, cachedData>> before removing them altogether.

NOTE: `clearCache` is used when the `CatalogImpl` is requested to link:spark-sql-Catalog.adoc#contract[clearCache].

=== [[recacheByCondition]] Re-Caching Structured Query -- `recacheByCondition` Internal Method

[source, scala]
----
recacheByCondition(spark: SparkSession, condition: LogicalPlan => Boolean): Unit
----

`recacheByCondition`...FIXME

NOTE: `recacheByCondition` is used when `CacheManager` is requested to <<uncacheQuery, uncache a structured query>>, <<recacheByPlan, recacheByPlan>>, and <<recacheByPath, recacheByPath>>.

=== [[recacheByPlan]] `recacheByPlan` Method

[source, scala]
----
recacheByPlan(spark: SparkSession, plan: LogicalPlan): Unit
----

`recacheByPlan`...FIXME

NOTE: `recacheByPlan` is used exclusively when `InsertIntoDataSourceCommand` logical command is <<spark-sql-LogicalPlan-InsertIntoDataSourceCommand.adoc#run, executed>>.

=== [[recacheByPath]] `recacheByPath` Method

[source, scala]
----
recacheByPath(spark: SparkSession, resourcePath: String): Unit
----

`recacheByPath`...FIXME

NOTE: `recacheByPath` is used exclusively when `CatalogImpl` is requested to link:spark-sql-CatalogImpl.adoc#refreshByPath[refreshByPath].

=== [[useCachedData]] Replacing Segments of Logical Query Plan With Cached Data -- `useCachedData` Method

[source, scala]
----
useCachedData(plan: LogicalPlan): LogicalPlan
----

`useCachedData`...FIXME

NOTE: `useCachedData` is used exclusively when `QueryExecution` is requested for a link:spark-sql-QueryExecution.adoc#withCachedData[cached logical query plan].
